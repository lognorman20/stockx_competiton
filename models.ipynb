{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600535178328",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as plticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Order Date   Brand                                   Sneaker Name  \\\n0      2017-09-01   Yeezy           Adidas Yeezy Boost 350 Low V2 Beluga   \n1      2017-09-01   Yeezy    Adidas Yeezy Boost 350 V2 Core Black Copper   \n2      2017-09-01   Yeezy     Adidas Yeezy Boost 350 V2 Core Black Green   \n3      2017-09-01   Yeezy       Adidas Yeezy Boost 350 V2 Core Black Red   \n4      2017-09-01   Yeezy  Adidas Yeezy Boost 350 V2 Core Black Red 2017   \n...           ...     ...                                            ...   \n99951  2019-02-13   Yeezy    adidas Yeezy Boost 350 V2 Static Reflective   \n99952  2019-02-13   Yeezy    adidas Yeezy Boost 350 V2 Static Reflective   \n99953  2019-02-13   Yeezy    adidas Yeezy Boost 350 V2 Static Reflective   \n99954  2019-02-13   Yeezy    adidas Yeezy Boost 350 V2 Static Reflective   \n99955  2019-02-13   Yeezy    adidas Yeezy Boost 350 V2 Static Reflective   \n\n       Sale Price  Retail Price Release Date  Shoe Size  Buyer Region  \n0            1097           220   2016-09-24       11.0    California  \n1             685           220   2016-11-23       11.0    California  \n2             690           220   2016-11-23       11.0    California  \n3            1075           220   2016-11-23       11.5      Kentucky  \n4             828           220   2017-02-11       11.0  Rhode Island  \n...           ...           ...          ...        ...           ...  \n99951         565           220   2018-12-26        8.0        Oregon  \n99952         598           220   2018-12-26        8.5    California  \n99953         605           220   2018-12-26        5.5      New York  \n99954         650           220   2018-12-26       11.0    California  \n99955         640           220   2018-12-26       11.5         Texas  \n\n[99956 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order Date</th>\n      <th>Brand</th>\n      <th>Sneaker Name</th>\n      <th>Sale Price</th>\n      <th>Retail Price</th>\n      <th>Release Date</th>\n      <th>Shoe Size</th>\n      <th>Buyer Region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas Yeezy Boost 350 Low V2 Beluga</td>\n      <td>1097</td>\n      <td>220</td>\n      <td>2016-09-24</td>\n      <td>11.0</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas Yeezy Boost 350 V2 Core Black Copper</td>\n      <td>685</td>\n      <td>220</td>\n      <td>2016-11-23</td>\n      <td>11.0</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas Yeezy Boost 350 V2 Core Black Green</td>\n      <td>690</td>\n      <td>220</td>\n      <td>2016-11-23</td>\n      <td>11.0</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas Yeezy Boost 350 V2 Core Black Red</td>\n      <td>1075</td>\n      <td>220</td>\n      <td>2016-11-23</td>\n      <td>11.5</td>\n      <td>Kentucky</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-09-01</td>\n      <td>Yeezy</td>\n      <td>Adidas Yeezy Boost 350 V2 Core Black Red 2017</td>\n      <td>828</td>\n      <td>220</td>\n      <td>2017-02-11</td>\n      <td>11.0</td>\n      <td>Rhode Island</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>99951</th>\n      <td>2019-02-13</td>\n      <td>Yeezy</td>\n      <td>adidas Yeezy Boost 350 V2 Static Reflective</td>\n      <td>565</td>\n      <td>220</td>\n      <td>2018-12-26</td>\n      <td>8.0</td>\n      <td>Oregon</td>\n    </tr>\n    <tr>\n      <th>99952</th>\n      <td>2019-02-13</td>\n      <td>Yeezy</td>\n      <td>adidas Yeezy Boost 350 V2 Static Reflective</td>\n      <td>598</td>\n      <td>220</td>\n      <td>2018-12-26</td>\n      <td>8.5</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>99953</th>\n      <td>2019-02-13</td>\n      <td>Yeezy</td>\n      <td>adidas Yeezy Boost 350 V2 Static Reflective</td>\n      <td>605</td>\n      <td>220</td>\n      <td>2018-12-26</td>\n      <td>5.5</td>\n      <td>New York</td>\n    </tr>\n    <tr>\n      <th>99954</th>\n      <td>2019-02-13</td>\n      <td>Yeezy</td>\n      <td>adidas Yeezy Boost 350 V2 Static Reflective</td>\n      <td>650</td>\n      <td>220</td>\n      <td>2018-12-26</td>\n      <td>11.0</td>\n      <td>California</td>\n    </tr>\n    <tr>\n      <th>99955</th>\n      <td>2019-02-13</td>\n      <td>Yeezy</td>\n      <td>adidas Yeezy Boost 350 V2 Static Reflective</td>\n      <td>640</td>\n      <td>220</td>\n      <td>2018-12-26</td>\n      <td>11.5</td>\n      <td>Texas</td>\n    </tr>\n  </tbody>\n</table>\n<p>99956 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "# Reading in the data\n",
    "shoe_data = pd.read_csv('/Users/logno/Documents/Home/BAF1/ds_shoe_proj/Clean_Shoe_Data.csv', parse_dates = True)\n",
    "df = shoe_data.copy()\n",
    "df"
   ]
  },
  {
   "source": [
    "# Data Cleaning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns to get rid of spaces \n",
    "df = df.rename(columns={\n",
    "    \"Order Date\": \"Order_date\",\n",
    "    \"Sneaker Name\": \"Sneaker_Name\",\n",
    "    \"Sale Price\": \"Sale_Price\",\n",
    "    \"Retail Price\": \"Retail_Price\",\n",
    "    \"Release Date\": \"Release_Date\",\n",
    "    \"Shoe Size\": \"Shoe_Size\",\n",
    "    \"Buyer Region\": \"Buyer_Region\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dates into numericals\n",
    "import datetime as dt\n",
    "\n",
    "df['Order_date'] = pd.to_datetime(df['Order_date'])\n",
    "df['Order_date']=df['Order_date'].map(dt.datetime.toordinal)\n",
    "\n",
    "df['Release_Date'] = pd.to_datetime(df['Release_Date'])\n",
    "df['Release_Date']=df['Release_Date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up train & test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['Sale_Price'], axis=1)\n",
    "y = df.Sale_Price\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X, y, test_size=0.2, random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical data to numerical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "object_cols = ['Sneaker_Name', 'Buyer_Region', 'Brand']\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# # Adding the column names after one hot encoding\n",
    "# OH_cols_train.columns = OH_encoder.get_feature_names(object_cols)\n",
    "# OH_cols_valid.columns = OH_encoder.get_feature_names(object_cols)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Order_date  Retail_Price  Release_Date  Shoe_Size    0    1    2    3  \\\n5827       736663           220        736658       11.0  0.0  0.0  0.0  0.0   \n168        736581           220        736385        8.0  0.0  0.0  0.0  0.0   \n80966      737055           170        737047        8.0  0.0  0.0  0.0  0.0   \n88639      737070           170        737047       10.0  0.0  0.0  0.0  0.0   \n3292       736657           160        736581       10.0  0.0  0.0  0.0  0.0   \n\n         4    5  ...   93   94   95   96   97   98   99  100  101  102  \n5827   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n168    0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n80966  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n88639  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n3292   0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n\n[5 rows x 107 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order_date</th>\n      <th>Retail_Price</th>\n      <th>Release_Date</th>\n      <th>Shoe_Size</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>...</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5827</th>\n      <td>736663</td>\n      <td>220</td>\n      <td>736658</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>736581</td>\n      <td>220</td>\n      <td>736385</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>80966</th>\n      <td>737055</td>\n      <td>170</td>\n      <td>737047</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>88639</th>\n      <td>737070</td>\n      <td>170</td>\n      <td>737047</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3292</th>\n      <td>736657</td>\n      <td>160</td>\n      <td>736581</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 107 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(79964, 107)"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Order_date  Retail_Price  Release_Date  Shoe_Size    0    1    2    3  \\\n30843      736865           190        736868        6.0  0.0  0.0  0.0  0.0   \n74873      737043           220        736651        9.0  0.0  0.0  0.0  0.0   \n99408      737102           160        737097        8.5  0.0  0.0  0.0  0.0   \n89424      737072           220        737055        9.0  0.0  0.0  0.0  0.0   \n76890      737047           220        737021        7.5  0.0  0.0  0.0  0.0   \n\n         4    5  ...   93   94   95   96   97   98   99  100  101  102  \n30843  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n74873  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n99408  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n89424  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n76890  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n\n[5 rows x 107 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order_date</th>\n      <th>Retail_Price</th>\n      <th>Release_Date</th>\n      <th>Shoe_Size</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>...</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n      <th>100</th>\n      <th>101</th>\n      <th>102</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>30843</th>\n      <td>736865</td>\n      <td>190</td>\n      <td>736868</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>74873</th>\n      <td>737043</td>\n      <td>220</td>\n      <td>736651</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>99408</th>\n      <td>737102</td>\n      <td>160</td>\n      <td>737097</td>\n      <td>8.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>89424</th>\n      <td>737072</td>\n      <td>220</td>\n      <td>737055</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>76890</th>\n      <td>737047</td>\n      <td>220</td>\n      <td>737021</td>\n      <td>7.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 107 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "source": [
    "# Pipelines Creation\n",
    "## 1. Data Preprocessing by using Standard Scaler\n",
    "## 2. Reduce Dimension using PCA\n",
    "## 3. Apply  Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression Pipeline\n",
    "pipeline_dtr=Pipeline([('dtr', DecisionTreeRegressor(random_state=27))])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "pipeline_randomforest=Pipeline([('rf_regressor',RandomForestRegressor(random_state=27))])\n",
    "\n",
    "# XGBost Pipeline\n",
    "pipeline_xgb=Pipeline([('xgb_regressor',xgb.XGBRegressor(objective=\"reg:linear\", random_state=27))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[20:04:17] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n[20:04:26] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\nDTR Test Accuracy: 0.9728403633364292\nXGBoost Test Accuracy: 0.9822455836271772\nRandomForest Test Accuracy: 0.9845200900515633\nClassifier with best accuracy: RandomForest\n"
    }
   ],
   "source": [
    "# Creating a list of the pipelines to loop through them\n",
    "pipelines = [pipeline_dtr, pipeline_xgb, pipeline_randomforest]\n",
    "\n",
    "best_accuracy=0.0\n",
    "best_regressor=0\n",
    "best_pipeline=\"\"\n",
    "\n",
    "# Dictionary of pipelines and regression types for ease of reference\n",
    "pipe_dict = {0: 'DTR', 1: 'XGBoost', 2: 'RandomForest'}\n",
    "\n",
    "# Fit the pipelines\n",
    "for pipe in pipelines:\n",
    "\tpipe.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Checking the accuracy of each model\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy: {}\".format(pipe_dict[i],model.score(X_valid,y_valid)))\n",
    "\n",
    "# Finding the best model\n",
    "for i,model in enumerate(pipelines):\n",
    "    if model.score(X_valid,y_valid)>best_accuracy:\n",
    "        best_accuracy=model.score(X_valid,y_valid)\n",
    "        best_pipeline=model\n",
    "        best_regressor=i\n",
    "print('Classifier with best accuracy: {}'.format(pipe_dict[best_regressor]))"
   ]
  },
  {
   "source": [
    "# Hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Random Forest Regressor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 5, 10],\n 'min_samples_split': [2, 5, 10, 15, 25, 50, 75, 100],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
    }
   ],
   "source": [
    "# Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 25, 50, 75, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 27.9min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(random_state=27),\n                   n_jobs=-1,\n                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n                                                      70, 80, 90, 100, None],\n                                        'max_features': ['auto', 'sqrt'],\n                                        'min_samples_leaf': [1, 2, 5, 10],\n                                        'min_samples_split': [2, 5, 10, 15, 25,\n                                                              50, 75, 100],\n                                        'n_estimators': [200, 400, 600, 800,\n                                                         1000, 1200, 1400, 1600,\n                                                         1800, 2000]},\n                   random_state=27, verbose=2)"
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "# THIS BLOCK TAKES EONS\n",
    "rf = RandomForestRegressor(random_state=27)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=27, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "\n",
    "# rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of Random Search\n",
    "def evaluate(model, X_valid, y_valid):\n",
    "    predictions = model.predict(X_valid)\n",
    "    errors = np.sqrt(mean_squared_error(y_valid, predictions))\n",
    "    print('Model Performance')\n",
    "    print('MSE of: ', errors)\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model Performance\nMSE of:  32.063612748765806\nModel Performance\nMSE of:  31.58548726338043\n\n\nBase Accuracy:  32.063612748765806\n\n\nRandom Accuracy:  31.58548726338043\nImprovement of -0.01%.\n\n\nRF_Randomized_Search_CV\n\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "base_model = rf\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_valid, y_valid)\n",
    "\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "best_random.fit(X_train , y_train)\n",
    "\n",
    "random_accuracy = evaluate(best_random, X_valid, y_valid)\n",
    "\n",
    "print('\\n')\n",
    "print('Base Accuracy: ', base_accuracy)\n",
    "print('\\n')\n",
    "print('Random Accuracy: ', random_accuracy)\n",
    "print('Improvement of {:0.2f}%.'.format((random_accuracy - base_accuracy) / base_accuracy))\n",
    "\n",
    "print('\\n')\n",
    "print('RF_Randomized_Search_CV')\n",
    "print('\\n')"
   ]
  },
  {
   "source": [
    "print(rf_random.best_estimator_)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 170,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RandomForestRegressor(max_depth=90, min_samples_split=5, n_estimators=2000,\n                      random_state=27)\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9812574395706246"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "source": [
    "Now to evaluate the accuracy of this hyperparametered model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new pipeline for best model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('model', best_random)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MAE scores:\n [17.81016796 17.49555009 17.86157493 18.62745766 17.22604194]\nAverage MAE score (across experiments):\n17.80415851830286\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X_valid, y_valid,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)\n",
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  }
 ]
}